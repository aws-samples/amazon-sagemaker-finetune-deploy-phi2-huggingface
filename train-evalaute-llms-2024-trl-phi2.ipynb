{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Fine-Tune Phi-2 on Amazon SageMaker\n",
    "\n",
    "This notebook walks you thorugh how to fine-tune Microsoft Phi-2 from Hugging Face using Amazon SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description\n",
    "\n",
    "Phi-2 is a Transformer with 2.7 billion parameters. It was trained using the same data sources as Phi-1.5, augmented with a new data source consisting of various NLP synthetic texts and filtered websites (for safety and educational value). When assessed against benchmarks testing common sense, language understanding, and logical reasoning, Phi-2 showcased nearly state-of-the-art performance among models with less than 13 billion parameters.\n",
    "\n",
    "If you are looking for a lightweight large language model with generalized capability, Phi-2 can be a good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning task\n",
    "Here we are fine-tuning the Phi-2 model using summarization samples from the Dolly dataset from Huggingface Hub. The goal is to improve the model's overall summarization capability."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Development Environment\n",
    "\n",
    "Our first step is to install Hugging Face Libraries we need on the client to correctly prepare our dataset and start our training/evaluations jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers \"datasets[s3]==2.18.0\" \"sagemaker>=2.190.0\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::275631959608:role/service-role/AmazonSageMaker-ExecutionRole-20231011T123445\n",
      "sagemaker bucket: sagemaker-us-east-1-275631959608\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session_bucket = None\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are going to use `trl: https://huggingface.co/docs/trl/en/index` for fine-tuning, which supports popular instruction and conversation dataset formats. This means we only need to convert our dataset to one of the supported formats and `trl` will take care of the rest. Those formats include:\n",
    "\n",
    "- conversational format\n",
    "\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```\n",
    "\n",
    "- instruction format\n",
    "\n",
    "```json\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "```\n",
    "\n",
    "In our example we are going to load open-source `dolly` dataset using the 🤗 Datasets library and then convert it into the the conversational format, where we include the schema definition in the system message for our assistant. We'll then save the dataset as jsonl file, which we can then use to fine-tune our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a text summarizer. Users will provide you a text in English and you will generate a summary based on the provided SCHEMA.\\nSCHEMA:\\nWhat is Sim racing', 'role': 'system'}, {'content': \"Simulated racing or racing simulation, commonly known as simply sim racing, are the collective terms for racing game software that attempts to accurately simulate auto racing, complete with real-world variables such as fuel usage, damage, tire wear and grip, and suspension settings. To be competitive in sim racing, a driver must understand all aspects of car handling that make real-world racing so difficult, such as threshold braking, how to maintain control of a car as the tires lose traction, and how properly to enter and exit a turn without sacrificing speed. It is this level of difficulty that distinguishes sim racing from arcade racing-style driving games where real-world variables are taken out of the equation and the principal objective is to create a sense of speed as opposed to a sense of realism.\\n\\n\\nJann Mardenborough, a sim racer became a professional Nissan racing driver by playing Gran Turismo.\\nDue to the complexity and demands of mimicking real-life driving, racing sims require faster computers to run effectively, as well as a steering wheel and pedals for the throttle and brakes for the immersion.\\n\\n\\nMany cars are digitally recreated for sim racing like this BMW Z4 GT3 from Assetto Corsa.\\nWhile using a simple gamepad, joystick or even a mouse and keyboard may suffice for most arcade-style driving games on home systems, it won't provide the same level of immersion and realism as using a racing wheel and pedals. In recent years, many sim racing experiences have been developed for consoles, such as the PlayStation and Xbox. While these games can be played with a controller, it is recommended that players invest in a racing wheel and pedals. With the development of online racing, the ability to drive against human opponents and computer AI offline is the closest many will come to driving cars on a real track. Even those who race in real-world competition use simulations for practice or for entertainment. With continued development of the physics engine software that forms the basis of these sims, as well as improved hardware (providing tactile feedback), the experience has become more realistic.\\n\\nIn general, sim racing gameplay style applied in several video games like iRacing, Assetto Corsa and Assetto Corsa Competizione, Gran Turismo, among others.\", 'role': 'user'}, {'content': 'Sim Racing is simulating car racing as accurately as possible using racing game software and hardware. To be competitive, drivers need to understand all aspects of car handling and setup. This creates a high level of complexity, which differentiates sim racing from arcade racing-style games.', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Convert dataset to OAI messages\n",
    "system_message = \"\"\"You are a text summarizer. Users will provide you a text in English and you will generate a summary based on the provided SCHEMA.\n",
    "SCHEMA:\n",
    "{schema}\"\"\"\n",
    "\n",
    "def create_conversation(sample):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message.format(schema=sample[\"instruction\"])},\n",
    "      {\"role\": \"user\", \"content\": sample[\"context\"]},\n",
    "      {\"role\": \"assistant\", \"content\": sample[\"response\"]}\n",
    "    ]\n",
    "  }\n",
    "\n",
    "# Load dataset from the hub\n",
    "#dataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\n",
    "dolly_dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "\n",
    "# Filter the dataset to include only summarization examples\n",
    "summarization_dataset = dolly_dataset.filter(lambda example: example[\"category\"] == \"summarization\")\n",
    "summarization_dataset = summarization_dataset.remove_columns(\"category\")\n",
    "\n",
    "#dataset = dataset.shuffle().select(range(12500))\n",
    "\n",
    "# Convert dataset to instruction format\n",
    "summarization_dataset = summarization_dataset.map(create_conversation, batched=False)\n",
    "# split dataset into 1,000 training samples and 2,50 test samples\n",
    "dataset = summarization_dataset.train_test_split(test_size=2500/12500)\n",
    "\n",
    "print(dataset[\"train\"][0][\"messages\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we processed the datasets we are going to use the [FileSystem integration](https://huggingface.co/docs/datasets/filesystems) to upload our dataset to S3. We are using the `sess.default_bucket()`, adjust this if you want to store the dataset in a different S3 bucket. We will use the S3 path later in our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341143c54da241f98585686bca4f73fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dabe06b18e420a9d0ded23a74a02e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to:\n",
      "s3://sagemaker-us-east-1-275631959608/datasets/summarization/train_dataset.json\n",
      "https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-275631959608/?region=us-east-1&prefix=datasets/summarization/\n"
     ]
    }
   ],
   "source": [
    "# Save training dataset to S3 using SageMaker session\n",
    "\n",
    "training_input_path = f's3://{sess.default_bucket()}/datasets/summarization'\n",
    "\n",
    "# save datasets to s3\n",
    "dataset[\"train\"].to_json(f\"{training_input_path}/train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(f\"{training_input_path}/test_dataset.json\", orient=\"records\")\n",
    "\n",
    "print(f\"Training data uploaded to:\")\n",
    "print(f\"{training_input_path}/train_dataset.json\")\n",
    "print(f\"https://s3.console.aws.amazon.com/s3/buckets/{sess.default_bucket()}/?region={sess.boto_region_name}&prefix={training_input_path.split('/', 3)[-1]}/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-Tune Phi-2 with QLoRA on Amazon SageMaker\n",
    "\n",
    "We are now ready to fine-tune our model. We will use the [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer) from `trl` to fine-tune our model. The `SFTTrainer` makes it straightfoward to supervise fine-tune open LLMs. \n",
    "\n",
    "We will use the dataset formatting, packing and PEFT features in our example. As peft method we will use [QLoRA](https://arxiv.org/abs/2305.14314) a technique to reduce the memory footprint of large language models during finetuning, without sacrificing performance by using quantization. \n",
    "\n",
    "In Addition to QLoRA we will leverage the new [Flash Attention 2 integrationg with Transformers](https://huggingface.co/docs/transformers/perf_infer_gpu_one#flash-attention-2) to speed up the training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {\n",
    "  ### SCRIPT PARAMETERS ###\n",
    "  'dataset_path': '/opt/ml/input/data/training/train_dataset.json', # path where sagemaker will save training dataset\n",
    "  'model_id': \"microsoft/phi-2\",           # or `mistralai/Mistral-7B-v0.1`\n",
    "  'max_seq_len': 3072,                               # max sequence length for model and packing of the dataset\n",
    "  'use_qlora': True,                                 # use QLoRA model\n",
    "  ### TRAINING PARAMETERS ###\n",
    "  'num_train_epochs': 3,                             # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                  # batch size per device during training\n",
    "  'gradient_accumulation_steps': 4,                  # number of steps before performing a backward/update pass\n",
    "  'gradient_checkpointing': True,                    # use gradient checkpointing to save memory\n",
    "  'optim': \"adamw_torch_fused\",                      # use fused adamw optimizer\n",
    "  'logging_steps': 10,                               # log every 10 steps\n",
    "  'save_strategy': \"epoch\",                          # save checkpoint every epoch\n",
    "  'learning_rate': 2e-4,                             # learning rate, based on QLoRA paper\n",
    "  'bf16': True,                                      # use bfloat16 precision\n",
    "  'tf32': True,                                      # use tf32 precision\n",
    "  'max_grad_norm': 0.3,                              # max gradient norm based on QLoRA paper\n",
    "  'warmup_ratio': 0.03,                              # warmup ratio based on QLoRA paper\n",
    "  'lr_scheduler_type': \"constant\",                   # use constant learning rate scheduler\n",
    "  'report_to': \"tensorboard\",                        # report metrics to tensorboard\n",
    "  'output_dir': '/tmp/tun',                          # Temporary output directory for model checkpoints\n",
    "  'merge_adapters': True,                            # merge LoRA adapters into model for easier deployment\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a sagemaker training job we need an `HuggingFace` Estimator. The Estimator handles end-to-end Amazon SageMaker training and deployment tasks. The Estimator manages the infrastructure use. Amazon SagMaker takes care of starting and managing all the required ec2 instances for us, provides the correct huggingface container, uploads the provided scripts and downloads the data from our S3 bucket into the container at `/opt/ml/input/data`. Then, it starts the training job by running.\n",
    "\n",
    "> Note: Make sure that you include the `requirements.txt` in the `source_dir` if you are using a custom training script. We recommend to just clone the whole repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f'phi2-7b-hf-text-to-sql-exp1'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_sft.py',    # train script\n",
    "    source_dir           = '../scripts/trl',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    disable_output_compression = True,        # not compress output to save training time and cost\n",
    "    environment          = {\n",
    "                            \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\", # set env variable to cache models in /tmp\n",
    "                            # \"HF_TOKEN\": \"REPALCE_WITH_YOUR_TOKEN\" # huggingface token to access gated models, e.g. llama 2\n",
    "                            }, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can also use `g5.2xlarge` instead of the `g5.4xlarge` instance type, but then it is not possible to use `merge_weights` parameter, since to merge the LoRA weights into the model weights, the model needs to fit into memory. But you could save the adapter weights and merge them using [merge_adapter_weights.py](../scripts/merge_adapter_weights.py) after training.\n",
    "\n",
    "We can now start our training job, with the `.fit()` method passing our S3 path to the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: phi2-7b-hf-text-to-sql-exp1-2024-03-25-20-42-18-255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-25 20:42:19 Starting - Starting the training job\n",
      "2024-03-25 20:42:19 Pending - Training job waiting for capacity...\n",
      "2024-03-25 20:42:45 Pending - Preparing the instances for training......\n",
      "2024-03-25 20:43:36 Downloading - Downloading the training image...............\n",
      "2024-03-25 20:45:51 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-03-25 20:46:47,413 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-03-25 20:46:47,431 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-25 20:46:47,441 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-03-25 20:46:47,442 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-03-25 20:46:48,825 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.38.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.7/130.7 kB 9.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.18.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.27.2 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: evaluate==0.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: bitsandbytes==0.42.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.42.0)\u001b[0m\n",
      "\u001b[34mCollecting trl==0.7.11 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading trl-0.7.11-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting peft==0.8.2 (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn==2.5.6 (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.5.6.tar.gz (2.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 102.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (3.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (2023.12.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.2->-r requirements.txt (line 1)) (4.66.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (15.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.70.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->-r requirements.txt (line 2)) (2023.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2->-r requirements.txt (line 3)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2->-r requirements.txt (line 3)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1->-r requirements.txt (line 4)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 5)) (1.11.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.11->-r requirements.txt (line 6)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.6->-r requirements.txt (line 8)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.6->-r requirements.txt (line 8)) (1.11.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->-r requirements.txt (line 1)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.2->-r requirements.txt (line 1)) (2023.7.22)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (0.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (13.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (1.6.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (2.16.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.27.2->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.11->-r requirements.txt (line 6)) (0.1.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 131.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.5/510.5 kB 68.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.0/280.0 kB 43.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading trl-0.7.11-py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 32.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.8.2-py3-none-any.whl (183 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 183.4/183.4 kB 35.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.5.6-cp310-cp310-linux_x86_64.whl size=120352136 sha256=63ab5a3883b67719671e154beb91522e2901cbe4af0c5e031306a06a85df0be5\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/a8/1c/88/b959d6818b98a46d61ba231683abb7523b89ac1a7ed1e0c206\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn, accelerate, transformers, datasets, trl, peft\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 2.3.6\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-2.3.6:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-2.3.6\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.25.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.25.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.25.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.36.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.36.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.36.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 2.15.0\u001b[0m\n",
      "\u001b[34mUninstalling datasets-2.15.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-2.15.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: trl\u001b[0m\n",
      "\u001b[34mFound existing installation: trl 0.7.4\u001b[0m\n",
      "\u001b[34mUninstalling trl-0.7.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled trl-0.7.4\u001b[0m\n",
      "\u001b[34mAttempting uninstall: peft\u001b[0m\n",
      "\u001b[34mFound existing installation: peft 0.7.1\u001b[0m\n",
      "\u001b[34mUninstalling peft-0.7.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled peft-0.7.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.27.2 datasets-2.18.0 flash-attn-2.5.6 peft-0.8.2 transformers-4.38.2 trl-0.7.11\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-03-25 20:47:07,318 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-25 20:47:07,318 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-25 20:47:07,361 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-25 20:47:07,396 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-25 20:47:07,431 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-25 20:47:07,443 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training/train_dataset.json\",\n",
      "        \"gradient_accumulation_steps\": 4,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"constant\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"max_seq_len\": 3072,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"microsoft/phi-2\",\n",
      "        \"num_train_epochs\": 3,\n",
      "        \"optim\": \"adamw_torch_fused\",\n",
      "        \"output_dir\": \"/tmp/tun\",\n",
      "        \"per_device_train_batch_size\": 1,\n",
      "        \"report_to\": \"tensorboard\",\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_qlora\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"phi2-7b-hf-text-to-sql-exp1-2024-03-25-20-42-18-255\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-275631959608/phi2-7b-hf-text-to-sql-exp1-2024-03-25-20-42-18-255/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_sft\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_sft.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training/train_dataset.json\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"constant\",\"max_grad_norm\":0.3,\"max_seq_len\":3072,\"merge_adapters\":true,\"model_id\":\"microsoft/phi-2\",\"num_train_epochs\":3,\"optim\":\"adamw_torch_fused\",\"output_dir\":\"/tmp/tun\",\"per_device_train_batch_size\":1,\"report_to\":\"tensorboard\",\"save_strategy\":\"epoch\",\"tf32\":true,\"use_qlora\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_sft.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_sft\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-275631959608/phi2-7b-hf-text-to-sql-exp1-2024-03-25-20-42-18-255/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training/train_dataset.json\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"constant\",\"max_grad_norm\":0.3,\"max_seq_len\":3072,\"merge_adapters\":true,\"model_id\":\"microsoft/phi-2\",\"num_train_epochs\":3,\"optim\":\"adamw_torch_fused\",\"output_dir\":\"/tmp/tun\",\"per_device_train_batch_size\":1,\"report_to\":\"tensorboard\",\"save_strategy\":\"epoch\",\"tf32\":true,\"use_qlora\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"phi2-7b-hf-text-to-sql-exp1-2024-03-25-20-42-18-255\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-275631959608/phi2-7b-hf-text-to-sql-exp1-2024-03-25-20-42-18-255/source/sourcedir.tar.gz\",\"module_name\":\"run_sft\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_sft.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training/train_dataset.json\",\"--gradient_accumulation_steps\",\"4\",\"--gradient_checkpointing\",\"True\",\"--learning_rate\",\"0.0002\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"constant\",\"--max_grad_norm\",\"0.3\",\"--max_seq_len\",\"3072\",\"--merge_adapters\",\"True\",\"--model_id\",\"microsoft/phi-2\",\"--num_train_epochs\",\"3\",\"--optim\",\"adamw_torch_fused\",\"--output_dir\",\"/tmp/tun\",\"--per_device_train_batch_size\",\"1\",\"--report_to\",\"tensorboard\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_qlora\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training/train_dataset.json\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=4\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=constant\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SEQ_LEN=3072\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=microsoft/phi-2\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIM=adamw_torch_fused\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/tun\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_REPORT_TO=tensorboard\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_QLORA=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_sft.py --bf16 True --dataset_path /opt/ml/input/data/training/train_dataset.json --gradient_accumulation_steps 4 --gradient_checkpointing True --learning_rate 0.0002 --logging_steps 10 --lr_scheduler_type constant --max_grad_norm 0.3 --max_seq_len 3072 --merge_adapters True --model_id microsoft/phi-2 --num_train_epochs 3 --optim adamw_torch_fused --output_dir /tmp/tun --per_device_train_batch_size 1 --report_to tensorboard --save_strategy epoch --tf32 True --use_qlora True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-03-25 20:47:07,444 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-03-25 20:47:07,444 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 950 examples [00:00, 61916.72 examples/s]\u001b[0m\n",
      "\u001b[34mUsing QLoRA\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/863 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 863/863 [00:00<00:00, 9.33MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 35.7k/35.7k [00:00<00:00, 161MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 41.9M/5.00G [00:00<00:14, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 83.9M/5.00G [00:00<00:12, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 136M/5.00G [00:00<00:11, 410MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▎         | 178M/5.00G [00:00<00:11, 402MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 220M/5.00G [00:00<00:12, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 262M/5.00G [00:00<00:12, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▋         | 315M/5.00G [00:00<00:12, 389MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 357M/5.00G [00:00<00:12, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 398M/5.00G [00:01<00:12, 363MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 451M/5.00G [00:01<00:11, 385MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 503M/5.00G [00:01<00:11, 405MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 545M/5.00G [00:01<00:11, 397MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 587M/5.00G [00:01<00:12, 362MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 629M/5.00G [00:01<00:12, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 671M/5.00G [00:01<00:12, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 724M/5.00G [00:01<00:11, 368MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▌        | 765M/5.00G [00:02<00:11, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 807M/5.00G [00:02<00:11, 369MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 849M/5.00G [00:02<00:11, 360MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 891M/5.00G [00:02<00:12, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▊        | 933M/5.00G [00:02<00:11, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 975M/5.00G [00:02<00:11, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 1.02G/5.00G [00:02<00:11, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 1.06G/5.00G [00:02<00:11, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 1.10G/5.00G [00:03<00:12, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 1.14G/5.00G [00:03<00:12, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▎       | 1.18G/5.00G [00:03<00:11, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 1.23G/5.00G [00:03<00:11, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▌       | 1.27G/5.00G [00:03<00:11, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 1.31G/5.00G [00:03<00:10, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 1.35G/5.00G [00:03<00:09, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 1.41G/5.00G [00:03<00:09, 393MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 1.45G/5.00G [00:04<00:09, 372MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 1.49G/5.00G [00:04<00:09, 383MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 1.54G/5.00G [00:04<00:08, 416MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 1.59G/5.00G [00:04<00:08, 406MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 1.64G/5.00G [00:04<00:08, 395MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▎      | 1.68G/5.00G [00:04<00:08, 393MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 1.73G/5.00G [00:04<00:07, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 1.77G/5.00G [00:04<00:07, 405MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 1.82G/5.00G [00:04<00:07, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 1.87G/5.00G [00:05<00:08, 388MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 1.91G/5.00G [00:05<00:08, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 1.95G/5.00G [00:05<00:08, 355MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|████      | 2.00G/5.00G [00:05<00:07, 376MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 2.04G/5.00G [00:05<00:07, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 2.09G/5.00G [00:05<00:07, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 2.13G/5.00G [00:05<00:07, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 2.17G/5.00G [00:05<00:07, 379MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 2.21G/5.00G [00:06<00:07, 355MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 2.25G/5.00G [00:06<00:07, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 2.30G/5.00G [00:06<00:08, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 2.35G/5.00G [00:06<00:07, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 2.39G/5.00G [00:06<00:07, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▊     | 2.43G/5.00G [00:06<00:07, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 2.47G/5.00G [00:06<00:07, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 2.53G/5.00G [00:06<00:06, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████▏    | 2.57G/5.00G [00:07<00:06, 369MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 2.61G/5.00G [00:07<00:06, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 2.66G/5.00G [00:07<00:05, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 2.71G/5.00G [00:07<00:06, 379MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 2.75G/5.00G [00:07<00:06, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 2.79G/5.00G [00:07<00:06, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 2.83G/5.00G [00:07<00:06, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 2.87G/5.00G [00:07<00:06, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 2.92G/5.00G [00:07<00:05, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 2.96G/5.00G [00:08<00:05, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 3.00G/5.00G [00:08<00:05, 384MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 3.04G/5.00G [00:08<00:05, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 3.08G/5.00G [00:08<00:05, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 3.12G/5.00G [00:08<00:05, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 3.17G/5.00G [00:08<00:05, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 3.21G/5.00G [00:08<00:05, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 3.25G/5.00G [00:08<00:05, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 3.29G/5.00G [00:09<00:05, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 3.33G/5.00G [00:09<00:05, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 3.39G/5.00G [00:09<00:04, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▊   | 3.43G/5.00G [00:09<00:04, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 3.47G/5.00G [00:09<00:04, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 3.51G/5.00G [00:09<00:04, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████▏  | 3.57G/5.00G [00:09<00:03, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 3.61G/5.00G [00:09<00:03, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 3.65G/5.00G [00:10<00:03, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 3.69G/5.00G [00:10<00:03, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 3.73G/5.00G [00:10<00:03, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 3.77G/5.00G [00:10<00:03, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▋  | 3.82G/5.00G [00:10<00:03, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 3.86G/5.00G [00:10<00:03, 311MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 3.90G/5.00G [00:11<00:04, 253MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 3.94G/5.00G [00:11<00:03, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 4.00G/5.00G [00:11<00:02, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 4.04G/5.00G [00:11<00:03, 318MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 4.08G/5.00G [00:11<00:03, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 4.13G/5.00G [00:11<00:02, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 4.18G/5.00G [00:11<00:02, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 4.23G/5.00G [00:11<00:02, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 4.27G/5.00G [00:11<00:01, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 4.31G/5.00G [00:12<00:01, 360MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 4.35G/5.00G [00:12<00:01, 368MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 4.39G/5.00G [00:12<00:01, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 4.44G/5.00G [00:12<00:01, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 4.48G/5.00G [00:12<00:01, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 4.52G/5.00G [00:12<00:01, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████▏| 4.56G/5.00G [00:12<00:01, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 4.60G/5.00G [00:12<00:01, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 4.65G/5.00G [00:13<00:01, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 4.69G/5.00G [00:13<00:00, 356MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 4.74G/5.00G [00:13<00:00, 385MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 4.78G/5.00G [00:13<00:00, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 4.82G/5.00G [00:13<00:00, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 4.88G/5.00G [00:13<00:00, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 4.92G/5.00G [00:13<00:00, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 4.96G/5.00G [00:13<00:00, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 5.00G/5.00G [00:14<00:00, 357MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:14<00:14, 14.06s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 41.9M/564M [00:00<00:03, 138MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 94.4M/564M [00:00<00:01, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 136M/564M [00:00<00:01, 247MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|██▉       | 168M/564M [00:00<00:01, 257MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 210M/564M [00:00<00:01, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 241M/564M [00:00<00:01, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|█████     | 283M/564M [00:01<00:00, 291MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 325M/564M [00:01<00:00, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▌   | 367M/564M [00:01<00:00, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 409M/564M [00:01<00:00, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 461M/564M [00:01<00:00, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 503M/564M [00:01<00:00, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 545M/564M [00:01<00:00, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 564M/564M [00:01<00:00, 304MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:15<00:00,  6.90s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:15<00:00,  7.97s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.93s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 124/124 [00:00<00:00, 1.17MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 7.34k/7.34k [00:00<00:00, 61.7MB/s]\u001b[0m\n",
      "\u001b[34mvocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mvocab.json: 100%|██████████| 798k/798k [00:00<00:00, 45.2MB/s]\u001b[0m\n",
      "\u001b[34mmerges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmerges.txt: 100%|██████████| 456k/456k [00:00<00:00, 37.0MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 35.9MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 1.08k/1.08k [00:00<00:00, 13.9MB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 1.30MB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mNo chat template is defined for this tokenizer - using a default chat template that implements the ChatML format (without BOS/EOS tokens!). If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\u001b[0m\n",
      "\u001b[34mNo chat template is defined for this tokenizer - using a default chat template that implements the ChatML format (without BOS/EOS tokens!). If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3920 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mToken indices sequence length is longer than the specified maximum sequence length for this model (3920 > 2048). Running this sequence through the model will result in indexing errors\u001b[0m\n",
      "\u001b[34mGenerating train split: 1 examples [00:00,  3.40 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 150 examples [00:00, 400.97 examples/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/111 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\u001b[0m\n",
      "\u001b[34m`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34m1%|          | 1/111 [00:10<19:58, 10.90s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 2/111 [00:21<19:20, 10.65s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 3/111 [00:31<19:01, 10.57s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 4/111 [00:42<18:46, 10.53s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 5/111 [00:52<18:33, 10.51s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 6/111 [01:03<18:22, 10.50s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 7/111 [01:13<18:10, 10.49s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 8/111 [01:24<18:02, 10.51s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 9/111 [01:34<17:50, 10.50s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 10/111 [01:45<17:39, 10.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.5752, 'grad_norm': 1.0390625, 'learning_rate': 0.0002, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m9%|▉         | 10/111 [01:45<17:39, 10.49s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 11/111 [01:55<17:28, 10.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 12/111 [02:06<17:17, 10.48s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 13/111 [02:16<17:06, 10.48s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 14/111 [02:27<16:56, 10.48s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 15/111 [02:37<16:45, 10.48s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 16/111 [02:48<16:37, 10.50s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 17/111 [02:58<16:26, 10.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 18/111 [03:09<16:15, 10.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 19/111 [03:19<16:04, 10.48s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 20/111 [03:30<15:53, 10.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.5351, 'grad_norm': 1.5859375, 'learning_rate': 0.0002, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 20/111 [03:30<15:53, 10.48s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 21/111 [03:40<15:42, 10.48s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 22/111 [03:50<15:32, 10.47s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 23/111 [04:01<15:21, 10.47s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 24/111 [04:11<15:11, 10.47s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 25/111 [04:22<15:00, 10.47s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 26/111 [04:32<14:50, 10.47s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 27/111 [04:43<14:39, 10.47s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 28/111 [04:53<14:29, 10.47s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 29/111 [05:04<14:18, 10.47s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 30/111 [05:14<14:08, 10.47s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.4832, 'grad_norm': 1.7578125, 'learning_rate': 0.0002, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 30/111 [05:14<14:08, 10.47s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 31/111 [05:25<13:57, 10.47s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 32/111 [05:35<13:47, 10.47s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 33/111 [05:46<13:36, 10.47s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 34/111 [05:56<13:26, 10.47s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 35/111 [06:07<13:15, 10.47s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 36/111 [06:17<13:05, 10.47s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 37/111 [06:28<12:54, 10.47s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 38/111 [06:39<12:58, 10.66s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 39/111 [06:49<12:43, 10.61s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 40/111 [07:00<12:30, 10.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.4511, 'grad_norm': 1.6796875, 'learning_rate': 0.0002, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 40/111 [07:00<12:30, 10.57s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 41/111 [07:10<12:17, 10.54s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 42/111 [07:21<12:05, 10.52s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 43/111 [07:31<11:54, 10.50s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 44/111 [07:41<11:43, 10.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 45/111 [07:52<11:32, 10.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 46/111 [08:02<11:21, 10.48s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 47/111 [08:13<11:10, 10.48s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 48/111 [08:23<10:59, 10.48s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 49/111 [08:34<10:49, 10.47s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 50/111 [08:44<10:38, 10.47s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.319, 'grad_norm': 1.9765625, 'learning_rate': 0.0002, 'epoch': 1.33}\u001b[0m\n",
      "\u001b[34m45%|████▌     | 50/111 [08:44<10:38, 10.47s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 51/111 [08:55<10:28, 10.47s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 52/111 [09:05<10:17, 10.47s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 53/111 [09:16<10:07, 10.47s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 54/111 [09:26<09:56, 10.47s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 55/111 [09:37<09:46, 10.47s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 56/111 [09:47<09:35, 10.47s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 57/111 [09:58<09:25, 10.47s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 58/111 [10:08<09:14, 10.47s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 59/111 [10:19<09:04, 10.47s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 60/111 [10:29<08:54, 10.47s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2466, 'grad_norm': 2.171875, 'learning_rate': 0.0002, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 60/111 [10:29<08:54, 10.47s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 61/111 [10:39<08:43, 10.47s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 62/111 [10:50<08:33, 10.47s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 63/111 [11:00<08:22, 10.47s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 64/111 [11:11<08:12, 10.47s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 65/111 [11:21<08:01, 10.47s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 66/111 [11:32<07:51, 10.47s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 67/111 [11:42<07:40, 10.47s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 68/111 [11:53<07:30, 10.47s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 69/111 [12:03<07:21, 10.51s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 70/111 [12:14<07:10, 10.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1324, 'grad_norm': 2.421875, 'learning_rate': 0.0002, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 70/111 [12:14<07:10, 10.50s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 71/111 [12:24<06:59, 10.49s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 72/111 [12:35<06:48, 10.48s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 73/111 [12:45<06:38, 10.48s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 74/111 [12:56<06:27, 10.48s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 75/111 [13:06<06:17, 10.47s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 76/111 [13:17<06:12, 10.65s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 77/111 [13:28<06:00, 10.59s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 78/111 [13:38<05:48, 10.56s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 79/111 [13:49<05:37, 10.53s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 80/111 [13:59<05:25, 10.51s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0712, 'grad_norm': 2.296875, 'learning_rate': 0.0002, 'epoch': 2.13}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 80/111 [13:59<05:25, 10.51s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 81/111 [14:10<05:15, 10.50s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 82/111 [14:20<05:04, 10.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 83/111 [14:31<04:53, 10.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 84/111 [14:41<04:43, 10.50s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 85/111 [14:52<04:32, 10.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 86/111 [15:02<04:22, 10.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 87/111 [15:13<04:11, 10.48s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 88/111 [15:23<04:01, 10.48s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 89/111 [15:33<03:50, 10.48s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 90/111 [15:44<03:39, 10.47s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0356, 'grad_norm': 2.140625, 'learning_rate': 0.0002, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m81%|████████  | 90/111 [15:44<03:39, 10.47s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 91/111 [15:54<03:29, 10.47s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 92/111 [16:05<03:19, 10.50s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 93/111 [16:15<03:08, 10.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 94/111 [16:26<02:58, 10.48s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 95/111 [16:36<02:47, 10.48s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 96/111 [16:47<02:37, 10.48s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 97/111 [16:57<02:26, 10.48s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 98/111 [17:08<02:16, 10.47s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 99/111 [17:18<02:05, 10.47s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 100/111 [17:29<01:55, 10.47s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0594, 'grad_norm': 2.703125, 'learning_rate': 0.0002, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 100/111 [17:29<01:55, 10.47s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 101/111 [17:39<01:44, 10.47s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 102/111 [17:50<01:34, 10.47s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 103/111 [18:00<01:23, 10.47s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 104/111 [18:11<01:13, 10.47s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 105/111 [18:21<01:02, 10.47s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 106/111 [18:32<00:52, 10.47s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 107/111 [18:42<00:41, 10.47s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 108/111 [18:52<00:31, 10.47s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 109/111 [19:03<00:20, 10.47s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 110/111 [19:13<00:10, 10.47s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.884, 'grad_norm': 2.65625, 'learning_rate': 0.0002, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 110/111 [19:13<00:10, 10.47s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 111/111 [19:24<00:00, 10.47s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 1164.7932, 'train_samples_per_second': 0.386, 'train_steps_per_second': 0.095, 'train_loss': 2.2517934683206917, 'epoch': 2.96}\u001b[0m\n",
      "\u001b[34m100%|██████████| 111/111 [19:24<00:00, 10.47s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 111/111 [19:24<00:00, 10.49s/it]\u001b[0m\n",
      "\u001b[34m['merges.txt', 'tokenizer.json', 'adapter_model.safetensors', 'vocab.json', 'tokenizer_config.json', 'special_tokens_map.json', 'README.md', 'checkpoint-37', 'runs', 'checkpoint-75', 'added_tokens.json', 'checkpoint-111', 'adapter_config.json']\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  6.14it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.96it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.98it/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2024-03-25 21:07:50,060 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-25 21:07:50,060 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-25 21:07:50,061 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-03-25 21:07:56 Uploading - Uploading generated training model\n",
      "2024-03-25 21:08:18 Completed - Training job completed\n",
      "Training seconds: 1497\n",
      "Billable seconds: 1497\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example for Phi-2, the SageMaker training job took `1497 seconds`, which is about `0.416 hours`. The ml.g5.4xlarge instance we used costs `$2.03 per hour` for on-demand usage. As a result, the total cost for training our Phi-2 model was only ~`$1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-275631959608/phi2-7b-hf-text-to-sql-exp1-2024-03-25-20-42-18-255/output/model/'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"].replace(\"s3://\", \"https://s3.console.aws.amazon.com/s3/buckets/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy & evaluate LLM on Amazon SageMaker and compare with the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py310\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.1-tgi1.4.0-gpu-py310-cu121-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.4.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a `HuggingFaceModel` using the container uri and the S3 path to our model. We also need to set our TGI configuration including the number of GPUs, max input tokens. You can find a full list of configuration options [here](https://huggingface.co/docs/text-generation-inference/basic_tutorials/launcher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time add the s3 path here\n",
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(1024), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(2048), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "fine_tuned_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py310\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    }
   ],
   "source": [
    "# We will also deploy the base Phi-2 model from Huggingface to compare the summarization performance\n",
    "\n",
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'microsoft/phi-2',\n",
    "\t'SM_NUM_GPUS': json.dumps(1)\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_base_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.4.2\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have created the HuggingFaceModel we can deploy it to Amazon SageMaker using the deploy method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2024-03-25-21-20-07-570\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2024-03-25-21-20-08-384\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2024-03-25-21-20-08-384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2024-03-25-21-24-40-613\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2024-03-25-21-24-41-300\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2024-03-25-21-24-41-300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "# Deploy tuned model to an endpoint\n",
    "tuned_llm = fine_tuned_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to give SageMaker the time to download the model\n",
    ")\n",
    "\n",
    "\n",
    "# Deploy base model to an endpoint\n",
    "base_llm = huggingface_base_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to give SageMaker the time to download the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_response: [{'generated_text': ' The chief engineers on the project are very focused on trying to resolve some of those software defects. ”\\nThe terms of reference for Surrey Council’s audit of recycling centre have been adopted and audit kick-offs are scheduled to take place in May. The audit commenced in August 2017 and its findings will be reported to Council at a special meeting scheduled on Monday, September 20, 2018. All findings will be reported to Council in three phases as follows: • Phase A: the findings from the'}]\n",
      "base_response: [{'generated_text': 'The long-awaited Eglinton Crosstown LRT continues without a completion date as the head of provincial transit agency Metrolinx warns the software “nerve centre” designed to run trains along the route is struggling with defects. Speaking on Monday, Metrolinx CEO Phil Verster said the line was moving forward but warned that software needed to run trains along the route continued to be a problem. The software is so problematic that, come June, it will already be on its seventh iteration, Verster said. All of the major construction is now complete,” Verster said, suggesting only minor tweaks like water leaks or broken tiles remain on the construction to-do list. What concerns me most, though, is the software defects in the signalling and train control system and the rectification of those defects by CTS and Alstom,” he said, referring to the contractors working on the line. They’re making good progress with it, but it’s not as fast as we would like it to be. Verster said he can’t say when the line will actually be operational and is hoping to have an answer soon. However, he added that it wouldn’t be possible to have an operational line this time in the winter. Constituents: Eglinton CrosstownLine extension starts today: Metrolinx hit by lengthy delays. Metrolinx picks Alstom to oversee critical CTS signalling work A catch-22 for Metrolinx Subway projects: Some have funding but'}]\n"
     ]
    }
   ],
   "source": [
    "inputs = \"The long-awaited Eglinton Crosstown LRT continues without a completion date as the head of provincial transit agency Metrolinx warns the software “nerve centre” designed to run trains along the route is struggling with defects. Speaking on Monday, Metrolinx CEO Phil Verster said the line was moving forward but warned that software needed to run trains along the route continued to be a problem. The software is so problematic that, come June, it will already be on its seventh iteration, Verster said. All of the major construction is now complete,” Verster said, suggesting only minor tweaks like water leaks or broken tiles remain on the construction to-do list. What concerns me most, though, is the software defects in the signalling and train control system and the rectification of those defects by CTS and Alstom,” he said, referring to the contractors working on the line. They’re making good progress with it, but it’s not as fast as we would like it to be.\"\n",
    "\n",
    "# send request\n",
    "tuned_response = tuned_llm.predict({\n",
    "\t\"inputs\": inputs,\n",
    "})\n",
    "\n",
    "# send request\n",
    "base_response = base_llm.predict({\n",
    "\t\"inputs\": inputs,\n",
    "})\n",
    "print (f\"tuned_response: {tuned_response}\")\n",
    "print (f\"base_response: {base_response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice that the output from the tuned model (fine-tuned with summarization data) is more concise and is of better quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-tgi-inference-2024-03-08-10-50-17-803\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: huggingface-pytorch-tgi-inference-2024-03-08-10-50-18-669\n",
      "INFO:sagemaker:Deleting endpoint with name: huggingface-pytorch-tgi-inference-2024-03-08-10-50-18-669\n"
     ]
    }
   ],
   "source": [
    "llm.delete_model()\n",
    "llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
